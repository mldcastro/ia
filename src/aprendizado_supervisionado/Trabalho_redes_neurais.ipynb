{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8g5GN3EpDn4b"
      },
      "source": [
        "\n",
        "Imports e definição do dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpxhsZya71hk"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "keras.utils.set_random_seed(812)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQhkJUZODtd1"
      },
      "source": [
        "Carregamento do dataset cifar-10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQQvrT5v785X"
      },
      "outputs": [],
      "source": [
        "# Carregar o conjunto de dados CIFAR-10\n",
        "cifar10 = keras.datasets.cifar10\n",
        "#Carrega duas tuplas, representando os dados de treinamento e de teste.\n",
        "#Cada tupla tem as imagens e os respectivos rótulos\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "num_classes = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwHzFJajDxZt"
      },
      "source": [
        "O código abaixo mostra as 10 primeiras imagens de treino e teste do cifar-10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "wJipJNqX9zsJ",
        "outputId": "91ceee79-6051-455e-9cfc-9b2c74390a33"
      },
      "outputs": [],
      "source": [
        "# Defina as classes do CIFAR-10\n",
        "class_names = ['Avião', 'Automóvel', 'Pássaro', 'Gato', 'Cervo',\n",
        "               'Cachorro', 'Sapo', 'Cavalo', 'Navio', 'Caminhão']\n",
        "\n",
        "# Crie um dicionário para mapear as classes para as imagens correspondentes\n",
        "class_to_image = {}\n",
        "for i in range(10):\n",
        "    index = (test_labels == i).nonzero()[0][0]  # Encontre o primeiro índice da classe\n",
        "    class_to_image[i] = test_images[index]\n",
        "\n",
        "# Mostre uma imagem de cada classe\n",
        "plt.figure(figsize=(10, 5))\n",
        "for i in range(10):\n",
        "    plt.subplot(2, 5, i + 1)\n",
        "    plt.xticks([])  # Remova os rótulos do eixo x\n",
        "    plt.yticks([])  # Remova os rótulos do eixo y\n",
        "    plt.imshow(class_to_image[i])\n",
        "    plt.xlabel(class_names[i])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZxLXNIaD4lq"
      },
      "source": [
        "Abaixo, convertemos os rótulos escalares (números de 0 a 9) para one-hot encoding.\n",
        "\n",
        "Não é necessário realizar este passo, caso seja utilizada a função de custo esparse_categorical_cross_entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0h1CJgPJ9MTt"
      },
      "outputs": [],
      "source": [
        "# Converter para codificação one-hot dos labels\n",
        "train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=num_classes)\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=num_classes)\n",
        "#Não é necessário se utilizar como função de custo esparse_categorical_cross_entropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nymnOpRMETAu"
      },
      "source": [
        "Função que retorna uma rede neural para o cifar-10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPrIRBmT8XiN"
      },
      "outputs": [],
      "source": [
        "# Crie o modelo de rede neural convolucional simples\n",
        "def get_cifar10_network():\n",
        "    model = keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),#(32, 32, 3) porque as imagens são 32X32 e RGB, portanto, tendo 3 canais de cor\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(num_classes, activation='softmax')  # 10 classes de saída\n",
        "    ])\n",
        "\n",
        "    # Compile o modelo\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',#pode ser substituída pela esparse_categorical_cross_entropy\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjmscwcQErIx"
      },
      "source": [
        "Trecho para treinar e avaliar a rede neural.\n",
        "O treino é realizado com os dados de treino e a avaliação do modelo é realizada nos dados de teste."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uN8v8_m8cvR",
        "outputId": "8fc65d80-77bf-4d3f-aa99-14cd9713ac0f"
      },
      "outputs": [],
      "source": [
        "# Treine o modelo\n",
        "model = get_cifar10_network()\n",
        "model.fit(train_images, train_labels, epochs=10)\n",
        "\n",
        "# Avalie o modelo no conjunto de teste\n",
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "print(f'Acurácia no conjunto de teste: {test_accuracy * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vc5-m031HdY0"
      },
      "source": [
        "Na célula abaixo, adicione o código para carregar os demais datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9l2VipoMHnmH"
      },
      "outputs": [],
      "source": [
        "# Inclua o código para carregar os demais datasets\n",
        "import numpy as np\n",
        "import numpy.typing as npt\n",
        "import typing\n",
        "\n",
        "from dataclasses import dataclass\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Dataset:\n",
        "    train_x: npt.NDArray[np.floating]\n",
        "    train_y: npt.NDArray[np.integer]\n",
        "\n",
        "    test_x: npt.NDArray[np.floating]\n",
        "    test_y: npt.NDArray[np.integer]\n",
        "\n",
        "    n_classes: int\n",
        "\n",
        "    @classmethod\n",
        "    def from_keras(\n",
        "        cls,\n",
        "        keras_dataset: tuple[\n",
        "            tuple[npt.NDArray, npt.NDArray], tuple[npt.NDArray, npt.NDArray]\n",
        "        ],\n",
        "        *,\n",
        "        n_classes: int,\n",
        "    ) -> typing.Self:\n",
        "        return cls(*keras_dataset[0], *keras_dataset[1], n_classes=n_classes)\n",
        "    \n",
        "    def to_categorical_labels(self) -> None:\n",
        "        self.train_y = tf.keras.utils.to_categorical(self.train_y, num_classes=self.n_classes)\n",
        "        self.test_y = tf.keras.utils.to_categorical(self.test_y, num_classes=self.n_classes)\n",
        "\n",
        "\n",
        "# mninst = keras.datasets.mnist\n",
        "# (train_images, train_labels), (test_images, test_labels) = mninst.load_data()\n",
        "# fashion_mnist = keras.datasets.fashion_mnist\n",
        "# (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "# cifar100 = keras.datasets.cifar100\n",
        "# (train_images, train_labels), (test_images, test_labels) = cifar100.load_data()\n",
        "# num_classes = 100\n",
        "\n",
        "cifar10 = Dataset.from_keras(keras.datasets.cifar10.load_data(), n_classes=10)\n",
        "cifar100 = Dataset.from_keras(\n",
        "    keras.datasets.cifar100.load_data(label_mode=\"fine\"), n_classes=100\n",
        ")\n",
        "mnist = Dataset.from_keras(keras.datasets.mnist.load_data(), n_classes=10)\n",
        "fashion_mnist = Dataset.from_keras(\n",
        "    keras.datasets.fashion_mnist.load_data(), n_classes=10\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKkBlEy1ExHj"
      },
      "source": [
        "Tarefa\n",
        "Escreva código para executar redes neurais nos seguintes datasets:\n",
        "\n",
        "MNIST (pode aproveitar o codigo existente)\n",
        "Fashion MNIST\n",
        "CIFAR-10\n",
        "CIFAR-100\n",
        "Cada execução deve ser por 10 épocas.\n",
        "\n",
        "Você deve preencher as funções a seguir para retornarem a rede neural com a melhor configuração que você conseguiu para cada dataset. O notebook deve ser entregue com a rede neural que obteve a melhor performance em cada conjunto de dados.\n",
        "\n",
        "IMPORTANTE: as funções não devem TREINAR nem AVALIAR as redes neurais, apenas instanciá-las e retorná-las.\n",
        "\n",
        "Ao final, preencha o dict results com o desempenho encontrado em cada execução."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gN14IpXnFfCQ"
      },
      "outputs": [],
      "source": [
        "def get_fashion_mnist_network():\n",
        "    num_classes = 10\n",
        "    model = tf.keras.models.Sequential(\n",
        "        name=\"fashion_mnist\",\n",
        "        layers=[\n",
        "            tf.keras.layers.Conv2D(\n",
        "                16, (3, 3), activation=\"relu\", input_shape=(28, 28, 1)\n",
        "            ),  # 1 camada de convolução: 16 filtros 3x3, stride padrão (1,1), ativação relu\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\"),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.MaxPool2D(\n",
        "                (2, 2),\n",
        "            ),\n",
        "            tf.keras.layers.Dropout(0.25),\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "            tf.keras.layers.Dense(num_classes, activation=\"softmax\"),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    model.compile(\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def get_mnist_network():\n",
        "    num_classes = 10\n",
        "    model = tf.keras.models.Sequential(\n",
        "        name=\"mnist\",\n",
        "        layers=[\n",
        "            tf.keras.layers.Conv2D(\n",
        "                16, (3, 3), activation=\"relu\", input_shape=(28, 28, 1)\n",
        "            ),  # 1 camada de convolução: 16 filtros 3x3, stride padrão (1,1), ativação relu\n",
        "            tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\"),\n",
        "            tf.keras.layers.MaxPool2D(\n",
        "                (2, 2),\n",
        "            ),\n",
        "            tf.keras.layers.Dropout(0.25),\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "            tf.keras.layers.Dense(num_classes, activation=\"softmax\"),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    model.compile(\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def get_cifar100_network():\n",
        "    num_classes = 100\n",
        "    model = keras.Sequential(\n",
        "        name=\"cifar100\",\n",
        "        layers=[\n",
        "            tf.keras.layers.Conv2D(\n",
        "                32, (3, 3), activation=\"relu\", input_shape=(32, 32, 3)\n",
        "            ),  # (32, 32, 3) porque as imagens são 32X32 e RGB, portanto, tendo 3 canais de cor\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
        "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "            tf.keras.layers.Dropout(0.25),\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "            tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "            tf.keras.layers.Dense(\n",
        "                num_classes, activation=\"softmax\"\n",
        "            ),  # 100 classes de saída\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Compile o modelo\n",
        "    model.compile(\n",
        "        optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# Você pode aproveitar as ideias do exemplo acima\n",
        "def get_cifar10_network():\n",
        "    num_classes = 10\n",
        "    model = keras.Sequential(\n",
        "        name=\"cifar10\",\n",
        "        layers=[\n",
        "            tf.keras.layers.Conv2D(\n",
        "                16, (3, 3), activation=\"relu\", input_shape=(32, 32, 3)\n",
        "            ),  # (32, 32, 3) porque as imagens são 32X32 e RGB, portanto, tendo 3 canais de cor\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\"),\n",
        "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "            tf.keras.layers.Dropout(0.25),\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "            tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "            tf.keras.layers.Dense(\n",
        "                num_classes, activation=\"softmax\"\n",
        "            ),  # 10 classes de saída\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Compile o modelo\n",
        "    model.compile(\n",
        "        optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Converter para codificação one-hot dos labels\n",
        "\n",
        "# train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=num_classes)\n",
        "# test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=num_classes)\n",
        "\n",
        "# Não é necessário se utilizar como função de custo esparse_categorical_cross_entropy\n",
        "\n",
        "cifar10.to_categorical_labels()\n",
        "cifar100.to_categorical_labels()\n",
        "mnist.to_categorical_labels()\n",
        "fashion_mnist.to_categorical_labels()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cifar10_model = get_cifar10_network()\n",
        "cifar10_model.fit(cifar10.train_x, cifar10.train_y, epochs=10)\n",
        "\n",
        "cifar100_model = get_cifar100_network()\n",
        "cifar100_model.fit(cifar100.train_x, cifar100.train_y, epochs=10)\n",
        "\n",
        "mnist_model = get_mnist_network()\n",
        "mnist_model.fit(mnist.train_x, mnist.train_y, epochs=10)\n",
        "\n",
        "fashion_mnist_model = get_fashion_mnist_network()\n",
        "fashion_mnist_model.fit(fashion_mnist.train_x, fashion_mnist.train_y, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "_datasets = (cifar10, cifar100, mnist, fashion_mnist)\n",
        "_models = (cifar10_model, cifar100_model, mnist_model, fashion_mnist_model)\n",
        "\n",
        "for dataset, model in zip(_datasets, _models):\n",
        "    test_loss, test_accuracy = model.evaluate(dataset.test_x, dataset.test_y)\n",
        "    print(f\"Acurácia no conjunto de teste: {test_accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iERVafMPF2Tn"
      },
      "source": [
        "Preencha o dict abaixo substituindo os None com a acuracia final (acc) e o tempo de treinamento (time) encontrado no seu experimento pra cada dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEUK1xk6Fk48"
      },
      "outputs": [],
      "source": [
        "results = {\n",
        "    \"mnist\": {\"time\": 441, \"acc\": 0.9932},\n",
        "    \"fashion_mnist\": {\"time\": 692, \"acc\": 0.9612},\n",
        "    \"cifar10\": {\"time\": 579, \"acc\": 0.7977},\n",
        "    \"cifar100\": {\"time\": 1278, \"acc\": 0.4246},\n",
        "}"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ufrgs-ia",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
